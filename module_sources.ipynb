{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "sys.path.append(os.environ['GADGETRON_HOME'] + '/share/gadgetron/python')\n",
    "\n",
    "#If Gadgetron is not installed, add the path from the gadgetron source folder\n",
    "#Set GADGETRON_SOURCE to point to the location of the Gadgetron source code\n",
    "#sys.path.append(os.environ['GADGETRON_SOURCE'] + '/gadgets/python/utils')\n",
    "#sys.path.append(os.environ['GADGETRON_SOURCE'] + '/gadgets/python/gadgets')\n",
    "\n",
    "import ismrmrd\n",
    "import ismrmrd.xsd\n",
    "import numpy as np\n",
    "from ismrmrdtools import show\n",
    "from gadgetron import Gadget\n",
    "from gadgetron import gadget_chain_wait\n",
    "from gadgetron import gadget_chain_config\n",
    "from gadgetron import get_last_gadget\n",
    "from tpat_snr_scale import RemOS, NoiseAdj, PCA, CoilReduce, Recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Gadget(object):\n",
      "    def __init__(self, next_gadget=None):\n",
      "        self.next_gadget = next_gadget\n",
      "        self.params = dict()\n",
      "        self.results = []\n",
      "\n",
      "    def set_parameter(self, name, value):\n",
      "        self.params[name] = value\n",
      "\n",
      "    def get_parameter(self, name):\n",
      "        return self.params.get(name, None)\n",
      "\n",
      "    def __call__(self, *args):\n",
      "        self.process(args)\n",
      "        return self.get_results()\n",
      "\n",
      "    def set_next_gadget(self, gadget):\n",
      "        self.next_gadget = gadget\n",
      "\n",
      "    def process_config(self, conf):\n",
      "        pass\n",
      "\n",
      "    def process(self, header, *args):\n",
      "        # do work here\n",
      "        self.put_next(header,*args)\n",
      "\n",
      "    def wait(self):\n",
      "        pass\n",
      "    \n",
      "    def put_next(self, *args):\n",
      "        if self.next_gadget is not None:\n",
      "            if isinstance(self.next_gadget, Gadget):\n",
      "                if len(args) == 3 and not isinstance(args[2],ismrmrd.Meta): #Data with meta data we assume\n",
      "                    meta = ismrmrd.Meta()\n",
      "                    meta = ismrmrd.Meta.deserialize(args[2])\n",
      "                    new_args = (args[0], args[1], meta)\n",
      "                    self.next_gadget.process(*new_args)\n",
      "                else:\n",
      "                    self.next_gadget.process(*args)\n",
      "            elif isinstance(self.next_gadget, GadgetronPythonMRI.GadgetReference):\n",
      "                if len(args) > 3:\n",
      "                    raise Exception(\"Only two or 3 return arguments are currently supported when returning to Gadgetron framework\")\n",
      "                if isinstance(args[0], ismrmrd.AcquisitionHeader):\n",
      "                    self.next_gadget.return_acquisition(args[0],args[1].astype('complex64'))\n",
      "                elif isinstance(args[0], ismrmrd.ImageHeader):\n",
      "                    header = args[0]\n",
      "                    if (args[1].dtype == np.uint16):\n",
      "                        if len(args) == 3:\n",
      "                            self.next_gadget.return_image_ushort_attr(header,args[1], args[2].serialize())\n",
      "                        else:\n",
      "                            self.next_gadget.return_image_ushort(header,args[1])\n",
      "                    elif (args[1].dtype == np.float32):\n",
      "                        if len(args) == 3:\n",
      "                            self.next_gadget.return_image_float_attr(header, args[1], args[2].serialize())\n",
      "                        else:\n",
      "                            self.next_gadget.return_image_float(header,args[1])\n",
      "                    else:\n",
      "                        if len(args) == 3:\n",
      "                            self.next_gadget.return_image_cplx_attr(header, args[1].astype('complex64'), args[2].serialize())\n",
      "                        else:\n",
      "                            self.next_gadget.return_image_cplx(header,args[1].astype('complex64'))\n",
      "                else:\n",
      "                    raise(\"Unsupported types when returning to Gadgetron framework\")\n",
      "            else:\n",
      "                raise(\"next_gadget is set to unsupported type\")\n",
      "        else:\n",
      "            self.results.append(list(args))\n",
      "\n",
      "    def get_results(self):\n",
      "        results = self.results\n",
      "        self.results = []\n",
      "        return results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(Gadget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NoiseAdj(Gadget):\n",
      "    def __init__(self, next_gadget = None):\n",
      "        Gadget.__init__(self, next_gadget)\n",
      "        self.noise_data = list()\n",
      "        self.noise_dmtx = None\n",
      "    def process(self,acq,data,*args):\n",
      "        if acq.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
      "            self.noise_data.append((acq,data))\n",
      "        else:\n",
      "            if len(self.noise_data):\n",
      "                profiles = len(self.noise_data)\n",
      "                channels = self.noise_data[0][1].shape[0]\n",
      "                samples_per_profile = self.noise_data[0][1].shape[1]\n",
      "                noise = np.zeros((channels,profiles*samples_per_profile),dtype=np.complex64)\n",
      "                counter = 0\n",
      "                for p in self.noise_data:\n",
      "                    noise[:,counter*samples_per_profile:(counter*samples_per_profile+samples_per_profile)] = p[1]\n",
      "                    counter = counter + 1\n",
      "                \n",
      "                scale = (acq.sample_time_us/self.noise_data[0][0].sample_time_us)*0.79\n",
      "                self.noise_dmtx = coils.calculate_prewhitening(noise,scale_factor=scale)\n",
      "                \n",
      "                #Test the noise adjust\n",
      "                d = self.noise_data[0][1]\n",
      "                d2 = coils.apply_prewhitening(d, self.noise_dmtx)                \n",
      "                self.noise_data = list()\n",
      "            \n",
      "            if self.noise_dmtx is not None:\n",
      "                data2 = coils.apply_prewhitening(data, self.noise_dmtx)\n",
      "            else:\n",
      "                data2 = data\n",
      "                \n",
      "            self.put_next(acq,data2)\n",
      "        return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(NoiseAdj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class PCA(Gadget):\n",
      "    def __init__(self, next_gadget=None):\n",
      "        Gadget.__init__(self, next_gadget) \n",
      "        self.calib_data = list()\n",
      "        self.pca_mtx = None\n",
      "        self.max_calib_profiles = 100\n",
      "        self.samples_to_use = 16\n",
      "        self.buffering = True\n",
      "        \n",
      "    def process(self,acq,data,*args):    \n",
      "        if self.buffering:\n",
      "            self.calib_data.append((acq,data))\n",
      "            \n",
      "            if (len(self.calib_data)>=self.max_calib_profiles or acq.isFlagSet(ismrmrd.ACQ_LAST_IN_SLICE)):\n",
      "                #We are done buffering calculate pca transformation\n",
      "                if self.samples_to_use < acq.number_of_samples:\n",
      "                    samp_to_use = self.samples_to_use\n",
      "                    \n",
      "                if (len(self.calib_data) < 16):\n",
      "                    samp_to_use = acq.number_of_samples\n",
      "                    \n",
      "                total_samples = samp_to_use*len(self.calib_data)\n",
      "                channels = data.shape[0]\n",
      "                \n",
      "                A = np.zeros((total_samples,channels), dtype=np.complex64)\n",
      "                counter = 0\n",
      "                for p in self.calib_data:\n",
      "                    d = p[1][:, acq.center_sample-(samp_to_use>>1):acq.center_sample+(samp_to_use>>1)]\n",
      "                    A[counter*samp_to_use:counter*samp_to_use+samp_to_use,:] = np.transpose(d)\n",
      "                    counter = counter+1\n",
      "                \n",
      "                m = np.mean(A,0)\n",
      "                A_m = A - m.reshape((1,m.shape[0]))\n",
      "                U, s, V = np.linalg.svd(A_m, full_matrices=False)\n",
      "                \n",
      "                self.pca_mtx = V\n",
      "                \n",
      "                #Empty calib_data\n",
      "                for p in self.calib_data:\n",
      "                    data2 = np.dot(self.pca_mtx,p[1])\n",
      "                    self.put_next(p[0],data2)\n",
      "     \n",
      "                self.buffering = False\n",
      "                self.calib_data = list()\n",
      "                return 0\n",
      "        else:\n",
      "            if self.pca_mtx is not None:\n",
      "                data2 = np.dot(self.pca_mtx,data)\n",
      "                self.put_next(acq,data2,*args)\n",
      "            else:\n",
      "                self.put_next(acq,data,*args)\n",
      "            \n",
      "        return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CoilReduce(Gadget):\n",
      "    def __init__(self, next_gadget = None):\n",
      "        Gadget.__init__(self, next_gadget)\n",
      "        self.coils_out = 16\n",
      "        \n",
      "    def process_config(self, conf):\n",
      "        coils_out = self.get_parameter(\"coils_out\")\n",
      "        if (coils_out is not None):\n",
      "            self.coils_out = int(coils_out)\n",
      "\n",
      "    def process(self, acq, data, *args):\n",
      "        if acq.active_channels > self.coils_out:\n",
      "            data2 = data[0:self.coils_out,:]\n",
      "            acq.active_channels = self.coils_out\n",
      "        else:\n",
      "            data2 = data\n",
      "            \n",
      "        self.put_next(acq,data2,*args)\n",
      "        return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(CoilReduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class RemOS(Gadget):\n",
      "    def process_config(self, conf):\n",
      "        return\n",
      "\n",
      "    def process(self, acq, data,*args):\n",
      "        if not acq.isFlagSet(ismrmrd.ACQ_IS_NOISE_MEASUREMENT):\n",
      "            ro_length = acq.number_of_samples\n",
      "            padded_ro_length = (acq.number_of_samples-acq.center_sample)*2\n",
      "            if padded_ro_length != ro_length: #partial fourier\n",
      "                data2 = np.zeros((data.shape[0], padded_ro_length),dtype=np.complex64)\n",
      "                offset = (padded_ro_length>>1)  - acq.center_sample\n",
      "                data2[:,0+offset:offset+ro_length] = data\n",
      "            else:\n",
      "                data2 = data\n",
      "    \n",
      "            data2=transform.transform_kspace_to_image(data2,dim=(1,))\n",
      "            data2=data2[:,(padded_ro_length>>2):(padded_ro_length>>2)+(padded_ro_length>>1)]\n",
      "            data2=transform.transform_image_to_kspace(data2,dim=(1,)) * np.sqrt(float(padded_ro_length)/ro_length)\n",
      "            acq.center_sample = padded_ro_length>>2\n",
      "            acq.number_of_samples = data2.shape[1]\n",
      "            self.put_next(acq,data2,*args)\n",
      "        return 0                                                                                     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(RemOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Recon(Gadget):\n",
      "    def __init__(self, next_gadget=None):\n",
      "        Gadget.__init__(self, next_gadget) \n",
      "        self.header = None\n",
      "        self.enc = None\n",
      "        self.acc_factor = None\n",
      "        self.buffer = None\n",
      "        self.samp_mask = None\n",
      "        self.header_proto = None\n",
      "        self.calib_buffer = list()\n",
      "        self.unmix = None\n",
      "        self.gmap = None\n",
      "        self.calib_frames = 0\n",
      "        self.method = 'grappa'\n",
      "    \n",
      "    def process_config(self, cfg):\n",
      "        self.header = ismrmrd.xsd.CreateFromDocument(cfg)\n",
      "        self.enc = self.header.encoding[0]\n",
      "\n",
      "        #Parallel imaging factor\n",
      "        self.acc_factor = self.enc.parallelImaging.accelerationFactor.kspace_encoding_step_1\n",
      "        \n",
      "        reps = self.enc.encodingLimits.repetition.maximum+1\n",
      "        phs = self.enc.encodingLimits.phase.maximum+1\n",
      "        if reps > phs:\n",
      "            self.calib_frames = reps\n",
      "        else:\n",
      "            self.calib_frames = phs\n",
      "            \n",
      "        if self.calib_frames < self.acc_factor:\n",
      "            self.calib_frames = self.acc_factor\n",
      "        \n",
      "        #Frames should be a multiple of the acceleration factor\n",
      "        self.frames = math.floor(self.calib_frames/self.acc_factor)*self.acc_factor\n",
      "\n",
      "        pmri_method =  self.get_parameter('pmri_method')\n",
      "        if pmri_method == 'grappa' or pmri_method == 'sense':\n",
      "            self.method = pmri_method\n",
      "\n",
      "    def process(self, acq, data,*args):\n",
      "\n",
      "        if self.buffer is None:\n",
      "            # Matrix size\n",
      "            eNx = self.enc.encodedSpace.matrixSize.x\n",
      "            eNy = self.enc.encodedSpace.matrixSize.y\n",
      "            eNz = self.enc.encodedSpace.matrixSize.z\n",
      "            rNx = self.enc.reconSpace.matrixSize.x\n",
      "            rNy = self.enc.reconSpace.matrixSize.y\n",
      "            rNz = self.enc.reconSpace.matrixSize.z\n",
      "\n",
      "            # Field of View\n",
      "            eFOVx = self.enc.encodedSpace.fieldOfView_mm.x\n",
      "            eFOVy = self.enc.encodedSpace.fieldOfView_mm.y\n",
      "            eFOVz = self.enc.encodedSpace.fieldOfView_mm.z\n",
      "            rFOVx = self.enc.reconSpace.fieldOfView_mm.x\n",
      "            rFOVy = self.enc.reconSpace.fieldOfView_mm.y\n",
      "            rFOVz = self.enc.reconSpace.fieldOfView_mm.z\n",
      "        \n",
      "            channels = acq.active_channels\n",
      "\n",
      "            if data.shape[1] != rNx:\n",
      "                raise(\"Error, Recon gadget expects data to be on correct matrix size in RO direction\")\n",
      "                \n",
      "            if (rNz != 1):\n",
      "                rasie(\"Error Recon Gadget only supports 2D for now\")\n",
      "                \n",
      "            self.buffer = np.zeros((channels, rNy, rNx),dtype=np.complex64)\n",
      "            self.samp_mask = np.zeros(self.buffer.shape[1:])\n",
      "            self.header_proto = ismrmrd.ImageHeader()\n",
      "            self.header_proto.matrix_size[0] = rNx\n",
      "            self.header_proto.matrix_size[1] = rNy\n",
      "            self.header_proto.matrix_size[2] = rNz\n",
      "            self.header_proto.field_of_view[0] = rFOVx\n",
      "            self.header_proto.field_of_view[1] = rFOVy\n",
      "            self.header_proto.field_of_view[0] = rFOVz\n",
      "        \n",
      "        #Now put data in buffer\n",
      "        line_offset = self.buffer.shape[1]/2 - self.enc.encodingLimits.kspace_encoding_step_1.center                                                                                 \n",
      "        self.buffer[:,acq.idx.kspace_encode_step_1+line_offset,:] = data                                                          \n",
      "        self.samp_mask[acq.idx.kspace_encode_step_1+line_offset,:] = 1\n",
      "        \n",
      "        #If last scan in buffer, do FFT and fill image header\n",
      "        if acq.isFlagSet(ismrmrd.ACQ_LAST_IN_ENCODE_STEP1) or acq.isFlagSet(ismrmrd.ACQ_LAST_IN_SLICE):\n",
      "            img_head = copy.deepcopy(self.header_proto)\n",
      "            img_head.position = acq.position                                                                                                                               \n",
      "            img_head.read_dir = acq.read_dir                                                                                                                               \n",
      "            img_head.phase_dir = acq.phase_dir                                                                                                                             \n",
      "            img_head.slice_dir = acq.slice_dir                                                                                                                             \n",
      "            img_head.patient_table_position = acq.patient_table_position                                                                                                   \n",
      "            img_head.acquisition_time_stamp = acq.acquisition_time_stamp                                                                                                   \n",
      "            img_head.slice = acq.idx.slice\n",
      "            img_head.channels = 1\n",
      "            \n",
      "            scale = self.samp_mask.size/(1.0*np.sum(self.samp_mask[:]));\n",
      "\n",
      "            #We have not yet calculated unmixing coefficients\n",
      "            if self.unmix is None:\n",
      "                self.calib_buffer.append((img_head,self.buffer.copy()))\n",
      "                self.buffer[:] = 0\n",
      "                self.samp_mask[:] = 0\n",
      "                \n",
      "                if len(self.calib_buffer) >= self.calib_frames:\n",
      "                    cal_data = np.zeros(self.calib_buffer[0][1].shape, dtype=np.complex64)\n",
      "                    for c in self.calib_buffer:\n",
      "                        cal_data = cal_data + c[1]\n",
      "                        \n",
      "                    mask = np.squeeze(np.sum(np.abs(cal_data),0))\n",
      "                    mask = np.ones(mask.shape)*(np.abs(mask)>0.0)\n",
      "                    target = None #cal_data[0:8,:,:]\n",
      "                    \n",
      "                    coil_images = transform.transform_kspace_to_image(cal_data,dim=(1,2))\n",
      "                    (csm,rho) = coils.calculate_csm_walsh(coil_images)\n",
      "                    \n",
      "                    if self.method == 'grappa':\n",
      "                        self.unmix, self.gmap = grappa.calculate_grappa_unmixing(cal_data, \n",
      "                                                                                 self.acc_factor, \n",
      "                                                                                 data_mask=mask, \n",
      "                                                                                 kernel_size=(4,5), \n",
      "                                                                                 csm=csm)\n",
      "                    elif self.method == 'sense':\n",
      "                        self.unmix, self.gmap = sense.calculate_sense_unmixing(self.acc_factor, csm)\n",
      "                    else:\n",
      "                        raise Exception('Unknown parallel imaging method: ' + str(self.method))\n",
      "                        \n",
      "                    for c in self.calib_buffer:\n",
      "                        recon = transform.transform_kspace_to_image(c[1],dim=(1,2))*np.sqrt(scale)\n",
      "                        recon = np.squeeze(np.sum(recon * self.unmix,0))\n",
      "                        self.put_next(c[0], recon,*args)\n",
      "                        \n",
      "                return 0\n",
      "                \n",
      "            if self.unmix is None:\n",
      "                raise Exception(\"We should never reach this point without unmixing coefficients\")\n",
      "                \n",
      "            recon = transform.transform_kspace_to_image(self.buffer,dim=(1,2))*np.sqrt(scale)\n",
      "            recon = np.squeeze(np.sum(recon * self.unmix,0))\n",
      "            self.buffer[:] = 0\n",
      "            self.samp_mask[:] = 0\n",
      "            self.put_next(img_head,recon,*args)\n",
      "        return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print inspect.getsource(Recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
